# SAGC Metagenomics Workshop, 2021

February 9<sup>th</sup>, Flinders at Tonsley, Adelaide, South Australia


We have created servers for you with all the software and data that you will need for these excercises. We are using the [human gut](../Datasets/gut) example data sets described here. Your instructors will provide details on how to log into the servers. If you can not log in, make sure you get some help!

We are going to step through a typical metagenomics analysis pipeline that you might run to see what is present in your data and to generate some metagenome assembled genomes. For each step, this manual provides detailed instructions, and there are also associated [YouTube videos](https://www.youtube.com/playlist?list=PLpPXw4zFa0uLMHwSZ7DMeLGjIUgo1IBbn) you can watch to learn more about the issues.

## [Quality Control and Preprocessing](../SequenceQC/) 


[QC and QA](../SequenceQC/) is the first step in making sure that you have good data analysis. Your result is only as good as your input.

This step will read the fastq files from the central location and save them in your account.

We iterate over each of the runs that have already been downloaded from the sequence read archive. Those runs are in `/data/gut/fastq`. First, we make a directory (`results/$SRR/prinseq`) to put the results, and then we run the prinseq command.

Lets break these parameters down and take a look. 

#### Filter on the length and overall quality

* `-min_len 60`   -- the minimum length of sequences to include. Assuming Illumina sequencing, you probably have read lengths between 150 and 300bp. Anything shorter will be a bad read. 
* `-min_qual_mean 25` -- minimum quality score for the mean of the read should be >25. (1 in 10^2.5 error ~ 1:300) which is about 1 bp error per read for 300 bp reads

#### Filter N's
Filter sequence with more than one N in the sequences. For Illumina reads, even a single N suggests a bad read.

* `-ns_max_n 1`  

#### Remove exact duplicate sequences
For (non-16S samples) we would expect exactly duplicated sequences to be diminishingly rare, and they are most likely an artefact of the sequencing reaction. Some sequencing technologies (those that involve amplification) are much more prone to this than others. 

* `-derep 1`


#### Poly A/T Trimming 
You can remove poly-A and poly-T sequences at the end of the read with at least 5 A's. These can be an artefact of mRNA sequencing.

* `-trim_tail_left 5`
* `-trim_tail_right 5` 

#### Quality based trimming of the reads
You can trim based on min, mean, max, or sum quality scores. In this case, trim using the min score. We take a window of size `trim_qual_window` bp (so in this case 10 bp) and remove it if the 
score is less than stated. So in this case, we trim 10 bp off either end if the score is less than 30. We repeat that until we have a 10 bp window whose min score >= 30.

* `-trim_qual_type min`
* `-trim_qual_left 30`
* `-trim_qual_right 30`
* `-trim_qual_window 10`

#### Output options
Control where things are written:

* `-out_format 0`  - output either fastq (0) or fasta (1) format sequences. 

The file names of reads 1 (R1) and reads 2 (R2) for paired (R1/2), single (unpaired reads, e.g. if the other read fails quality) (S1/2), or bad (b1/2) reads 

* For the paired reads, we create new paired end files: `-out_good results/$SRR/prinseq/${SRR}_1.fastq -out_good2 results/$SRR/prinseq/${SRR}_2.fastq`
* For the singleton reads we write them to a single file: `-out_single results/$SRR/prinseq/${SRR}_single.fastq -out_single2 results/$SRR/prinseq/${SRR}_single.fastq`
* For the "bad" reads, we don't store them: `-out_bad /dev/null -out_bad2 /dev/null`


#### Input reads
We have paired reads, so we include both fastq and fastq2:

* `-fastq /data/gut/fastq/${SRR}_pass_1.fastq.gz -fastq2 /data/gut/fastq/${SRR}_pass_2.fastq.gz`

#### Threads
This just means use more computers!



```bash
for SRR in SRR3466404 SRR3506419 SRR3506420 SRR3546776 SRR3546778 SRR3546779 SRR3546780 SRR3546781 SRR3546782; do 
    echo $SRR; 
    mkdir -p results/$SRR/prinseq; 
    prinseq++ -min_len 60 -min_qual_mean 25 -ns_max_n 1 -derep 1 -out_format 0 -trim_tail_left 5 \
              -trim_tail_right 5 -trim_qual_type min -trim_qual_left 30 -trim_qual_right 30 -trim_qual_window 10 \
              -out_good results/$SRR/prinseq/${SRR}_1.fastq -out_good2 results/$SRR/prinseq/${SRR}_2.fastq \
              -out_single results/$SRR/prinseq/${SRR}_single.fastq -out_single2 results/$SRR/prinseq/${SRR}_single.fastq \
              -out_bad /dev/null -out_bad2 /dev/null \
              -fastq /data/gut/fastq/${SRR}_pass_1.fastq.gz -fastq2 /data/gut/fastq/${SRR}_pass_2.fastq.gz -threads 4;
done
```


### Output files

[prinseq++](https://github.com/Adrian-Cantu/PRINSEQ-plus-plus) outputs DNA sequences in (usually) fastq format that have the bad sequences removed. If you have paired end reads, there will be a file for each paired end, plus singletons files for reads where one end passed QC but the other did not. There is also a file for reads that fail QC, but in this instance we do not save those reads.

## Who is there (part 1)?

For the first part of understanding which microbes are in the sample, we are going to use [FOCUS](../FOCUS/). 

This approach uses a heuristic to tell you what is in the sample. It doesn't map reads, but instead counts _k_-mers and maps those to a database of known genomes.

The options for this are straightforward: `-q results/$SRR/prinseq` is the output directory from prinseq, above, and `-o results/$SRR/focus` is where to write the results to. We use the default parameters for the rest of the operations, but you can also use a different _k_-mer size (by default _k_=6 and _k_=7 are installed in the servers). 


```bash
for SRR in SRR3466404 SRR3506419 SRR3506420 SRR3546776 SRR3546778 SRR3546779 SRR3546780 SRR3546781 SRR3546782; do
    echo $SRR;
    focus -q results/$SRR/prinseq -o results/$SRR/focus -t 4; 
done
```

### Output files

[focus](https://github.com/metageni/FOCUS) outputs comma separated files that contain the taxonomic information identified in your sequences. The proportions are summarised at different taxonomic levels. These `.csv` files can be imported directly into a spreadsheet program to graph or summarise the data. The output files are:


* output_All_levels.csv
* output_Kingdom_tabular.csv
* output_Phylum_tabular.csv
* output_Class_tabular.csv
* output_Order_tabular.csv
* output_Family_tabular.csv
* output_Genus_tabular.csv
* output_Species_tabular.csv
* output_Strain_tabular.csv

## Who is there (part 2)

For the second approach to understand which microbes are int he sample, we are going to use [Kraken2](../Kraken2).

This approach users _k_-mers to map the sequences in your sample to known genomes. It does this on a read-by-read basis.

There are [several databases readily available for Kraken2](https://benlangmead.github.io/aws-indexes/k2) and for this tutorial we have used the [Standard-8](https://genome-idx.s3.amazonaws.com/kraken/standard_8gb_20201202/inspect.txt) database (because it is smaller and so loads into memory). <small>To make life easier, we have set up kraken2 so that you do not need to provide the database name or location. If you install kraken2 yourself, you may need to add that here.</small>

Kraken also makes extensive use of the [NCBI Taxonomy](https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi) database.


```bash
for SRR in SRR3466404 SRR3506419 SRR3506420 SRR3546776 SRR3546778 SRR3546779 SRR3546780 SRR3546781 SRR3546782; do
    echo $SRR;
    mkdir -p results/$SRR/kraken/;
    kraken2 --paired --threads 4 \
    --report results/$SRR/kraken/$SRR.kraken_taxonomy.txt \
    --output results/$SRR/kraken/$SRR.kraken_output.txt \
    results/$SRR/prinseq/${SRR}_1.fastq results/$SRR/prinseq/${SRR}_2.fastq
done
```

### Output files

We have elected to output two files:

* `$SRR.kraken_output.txt` contains the [standard kraken output](https://github.com/DerrickWood/kraken2/wiki/Manual#output-formats):
    - A code (_C_ or _U_) indicating whether the read was classified or not
    - The read ID from the fastq file
    - The taxonomy ID assigned to the read if it is classified, or 0 if it is not classified
    - The length of the sequence in base pairs. Because we are using paired end reads, there are two lengths (R1|R2)
    - A space-separated list of the lowest common ancestor for each sequence that indicates how many kmers map to which taxonomic IDs. Because we have paired end information, there is a `|:|` separator between the R1 and R2 information
* `$SRR.kraken_taxonomy.txt` contains the [standard kraken report](https://github.com/DerrickWood/kraken2/wiki/Manual#sample-report-output-format):
    - Percent of fragments at that taxonomic level
    - Number of fragments at that taxonomic level (the sum of fragments at this level and all those below this level)
    - Number of fragments exactly at that taxonomic level
    - A taxonomic level code:  `U`nclassified, `R`oot, `D`omain, `K`ingdom, `P`hylum, `C`lass, `O`rder, `F`amily, `G`enus, or `S`pecies. If the taxonomy is not one of these the number indicates the levels between this node and the appropriate node. See [the docs](https://github.com/DerrickWood/kraken2/wiki/Manual#sample-report-output-format) for more information.
    - NCBI Taxonomic name
    - Scientific name




